# MiniLLMLib

Minimalist Python library for flexible, multi-provider LLM interaction.

---

**MiniLLMLib** enables advanced, provider-agnostic LLM workflows with a simple, extensible API. 

- 🧩 Flexible chat node system: thread & loom (tree) conversations
- 🔌 Supports OpenAI, Anthropic, Mistral, HuggingFace, custom URLs
- ⚡ Sync & async API, audio, JSON, advanced message formatting
- 💾 Save/load conversations, cost tracking, CLI & frontend-ready
- 🛠️ Easy model switching, parameter config, extensibility

## Why MiniLLMLib?
- Unified interface for all major LLM providers
- Minimal dependencies, clean design
- Built for research, experimentation, and production

---

## Get Started
- [Quickstart & Usage](usage.md)
- [Provider Matrix](providers.md)
- [Configuration](configuration.md)
- [Contributing](contributing.md)

---

[GitHub Repo](https://github.com/qfeuilla/MiniLLMLib) · [PyPI (coming soon)]()

```{toctree}
:maxdepth: 2

usage.md
providers.md
configuration.md
contributing.md
extending.md
troubleshooting.md
```
