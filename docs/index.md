# MiniLLMLib

Minimalist Python library for flexible, multi-provider LLM interaction.

---

**MiniLLMLib** enables advanced, provider-agnostic LLM workflows with a simple, extensible API. 

- ğŸ§© Flexible chat node system: thread & loom (tree) conversations
- ğŸ”Œ Supports OpenAI, Anthropic, Mistral, HuggingFace, custom URLs
- âš¡ Sync & async API, audio, JSON, advanced message formatting
- ğŸ’¾ Save/load conversations, cost tracking, CLI & frontend-ready
- ğŸ› ï¸ Easy model switching, parameter config, extensibility

## Why MiniLLMLib?
- Unified interface for all major LLM providers
- Minimal dependencies, clean design
- Built for research, experimentation, and production

---

## Get Started
- [Quickstart & Usage](usage.md)
- [Provider Matrix](providers.md)
- [Configuration](configuration.md)
- [Contributing](contributing.md)

---

[GitHub Repo](https://github.com/qfeuilla/MiniLLMLib) Â· [PyPI](https://pypi.org/project/minillmlib/)

```{toctree}
:maxdepth: 2

usage.md
providers.md
configuration.md
contributing.md
extending.md
troubleshooting.md
```
